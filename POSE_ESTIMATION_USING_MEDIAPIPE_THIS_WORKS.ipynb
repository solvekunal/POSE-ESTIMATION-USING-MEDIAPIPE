{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6262cec-6c51-4fcf-93b6-8cae82e2b2e8",
   "metadata": {},
   "source": [
    "# POSE ESTIMATION ON LIVE VIDEO USING MEDIAPIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ff8936-4907-487c-859a-744d1bfdc081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (0.10.14)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: opencv-python in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: jaxlib in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: matplotlib in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (3.8.4)\n",
      "Requirement already satisfied: numpy in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (4.25.4)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from jax->mediapipe) (1.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new_downloads_default_folder\\anaconda_destination_folder\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b796d04-6ec7-45a1-9945-a15e758af087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb340745-1f83-450c-8788-c9a79d00b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\new_downloads_default_folder\\anaconda_destination_folder\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Initialize the webcam or use a video file.\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam. You can also specify a video file path.\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the image to RGB.\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform pose estimation.\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    # Draw the pose annotations on the image.\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Display the resulting image.\n",
    "    cv2.imshow('Pose Estimation', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254b16c-9d0b-4d2f-848c-a48ac69b2d34",
   "metadata": {},
   "source": [
    "# POSE ESTIMATION(WITHOUT AUDI) ON SAVED VIDEO USING MEDIAPIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cafbf896-656b-410e-89ee-a67490130700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose and Drawing modules.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Specify the video file path.\n",
    "video_path = R'E:\\jupyter_notebook\\Videos\\tandav1.mp4'  # Replace with your video file path\n",
    "output_path = r'E:\\jupyter_notebook\\Videos\\tandav1_pose_estimation_output1.mp4'  # Specify the output video file path\n",
    "\n",
    "# Open the video file.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video frame width, height, and frames per second.\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create a VideoWriter object to save the output video.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize the pose estimation model.\n",
    "with mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform pose estimation.\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Draw the pose annotations on the image.\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Write the frame to the output video.\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the video file and close the output video.\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Close all OpenCV windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b8b43-7688-48fe-afff-e020bc38ed9c",
   "metadata": {},
   "source": [
    "# POSE ESTIMATION (WITH AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a637c65-dbd5-42ca-be55-0969a22f6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee829dd-73a6-497f-8dcb-a90dbc2d20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video E:\\jupyter_notebook\\Videos\\lovely2_pose_estimation_output_with_audio.mp4.\n",
      "MoviePy - Writing audio in lovely2_pose_estimation_output_with_audioTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video E:\\jupyter_notebook\\Videos\\lovely2_pose_estimation_output_with_audio.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready E:\\jupyter_notebook\\Videos\\lovely2_pose_estimation_output_with_audio.mp4\n",
      "Pose estimation video saved with original audio!\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Pose and Drawing modules.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Specify the video file path.\n",
    "video_path = R'E:\\jupyter_notebook\\Videos\\lovely2.mp4'  # Replace with your video file path\n",
    "output_path = r'E:\\jupyter_notebook\\Videos\\lovely2_pose_estimation_no_audio.mp4'  # Intermediate output video file (no audio)\n",
    "final_output_path = r'E:\\jupyter_notebook\\Videos\\lovely2_pose_estimation_output_with_audio.mp4'  # Final output with audio\n",
    "\n",
    "# Open the video file.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video frame width, height, and frames per second.\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create a VideoWriter object to save the output video.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize the pose estimation model.\n",
    "with mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform pose estimation.\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Draw the pose annotations on the image.\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Write the frame to the output video.\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the video file and close the output video.\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Close all OpenCV windows.\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Now add the original audio to the output video using moviepy.\n",
    "# Load the video with pose estimation.\n",
    "video_clip = VideoFileClip(output_path)\n",
    "\n",
    "# Extract the original audio.\n",
    "original_audio = AudioFileClip(video_path)\n",
    "\n",
    "# Set the original audio to the video clip.\n",
    "final_clip = video_clip.set_audio(original_audio)\n",
    "\n",
    "# Write the final video file with the original audio.\n",
    "final_clip.write_videofile(final_output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "print(\"Pose estimation video saved with original audio!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e60ad-b8f0-42ba-ae5a-07aed2ee031a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f67f5-0ad6-4467-bb2e-37198b14ace7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dea55e-8184-4779-ba3e-438c7ecc716f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d3ab6-6f87-4099-8231-a3beaa94ff63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25fd9d-3676-46ed-98ec-ffd3b5ed3e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
